{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS=12000\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=DIMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_text(datapoint):\n",
    "    \n",
    "    word_index = reuters.get_word_index()\n",
    "    reversed_word_index = dict([(value, key) for key,value in word_index.items()])\n",
    "    decoded_result = ' '.join([reversed_word_index.get(c-3, '?') for c in datapoint])\n",
    "    return decoded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? shr 49 cts vs 39 cts net 886 937 vs 892 323 revs 25 9 mln vs 23 7 mln year shr 1 78 dlr vs 1 34 dlr net 3 254 301 vs 2 472 676 revs 100 6 mln vs 87 4 mln note 1986 4th qtr and year net includes income loss of ? subsidiary of 14 881 dlrs and 311 848 dlrs or 17 cts per share respectively 1985 4th qtr and year net includes loss in ? unit of 108 598 dlrs and 298 412 dlrs or 16 cts per share respectively reuter 3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news_text(train_data[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_inputs(sequences, dims=DIMS):\n",
    "    \n",
    "    results = np.zeros((len(sequences), dims))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        results[i, seq] = 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "X_train = vectorized_inputs(train_data)\n",
    "X_test = vectorized_inputs(test_data)\n",
    "\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(DIMS,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/25\n",
      "8982/8982 [==============================] - 5s 602us/step - loss: 1.7158 - acc: 0.6398 - val_loss: 1.1618 - val_acc: 0.7453\n",
      "Epoch 2/25\n",
      "8982/8982 [==============================] - 4s 458us/step - loss: 0.7746 - acc: 0.8290 - val_loss: 0.9494 - val_acc: 0.7796\n",
      "Epoch 3/25\n",
      "8982/8982 [==============================] - 4s 454us/step - loss: 0.4343 - acc: 0.9047 - val_loss: 0.9256 - val_acc: 0.7872\n",
      "Epoch 4/25\n",
      "8982/8982 [==============================] - 4s 452us/step - loss: 0.2804 - acc: 0.9363 - val_loss: 0.9245 - val_acc: 0.8023\n",
      "Epoch 5/25\n",
      "8982/8982 [==============================] - 4s 445us/step - loss: 0.2148 - acc: 0.9483 - val_loss: 0.9652 - val_acc: 0.7956\n",
      "Epoch 6/25\n",
      "8982/8982 [==============================] - 4s 449us/step - loss: 0.1907 - acc: 0.9511 - val_loss: 1.0035 - val_acc: 0.7952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4158d2cf28>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=25, validation_data=(X_test, y_test), callbacks=[EarlyStopping(patience=2, mode='min')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do\n",
    "\n",
    "- try using a single hidden layer, or three hidden layers\n",
    "- use 128 units in hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
